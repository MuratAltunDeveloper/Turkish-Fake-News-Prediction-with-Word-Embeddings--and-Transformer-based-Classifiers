{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdkopnkZjdwc",
        "outputId": "4f590e2a-1cc7-436e-8119-65d5fc4a1133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting torch==2.4.1 (from torchvision)\n",
            "  Using cached torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1->torchvision)\n",
            "  Using cached triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
            "Using cached torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1\n",
            "    Uninstalling torch-2.2.1:\n",
            "      Successfully uninstalled torch-2.2.1\n",
            "Successfully installed nvidia-cudnn-cu12-9.1.0.70 nvidia-nccl-cu12-2.20.5 torch-2.4.1 triton-3.0.0\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.34.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.34.2\n",
            "    Uninstalling accelerate-0.34.2:\n",
            "      Successfully uninstalled accelerate-0.34.2\n",
            "Successfully installed accelerate-1.0.1\n",
            "Collecting transformers==4.28.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl.metadata (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2024.8.30)\n",
            "Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.0\n",
            "Name: transformers\n",
            "Version: 4.28.0\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, tokenizers, tqdm\n",
            "Required-by: \n",
            "---\n",
            "Name: accelerate\n",
            "Version: 1.0.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: \n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "! pip install torch==2.2.1\n",
        "!pip install torchvision --upgrade\n",
        "!pip install accelerate>=0.20.1\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install -U transformers==4.28.0\n",
        "!pip show transformers accelerate\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **# # YANLIŞLIKLA XX.XX% FORMATINI ELDE EDERKEN CONFUSİON MATRİSİNİ SİLDİM BU KOD EN İYİ BERT CONFUSİON MATRİS KODU**"
      ],
      "metadata": {
        "id": "k9hp4hGGz5V0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM_ktJSxxM5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14070a7-885e-44a3-a32c-2f730a2281ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.28.0\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, tokenizers, tqdm\n",
            "Required-by: \n",
            "---\n",
            "Name: accelerate\n",
            "Version: 1.0.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: \n",
            "Files removed: 114\n"
          ]
        }
      ],
      "source": [
        "!pip show transformers accelerate\n",
        "!pip cache purge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lt93eHaLuhe"
      },
      "outputs": [],
      "source": [
        "import google.colab\n",
        "from google.colab import files\n",
        "\n",
        "# Hugging Face Hub token'ını secrets modülü ile sakla\n",
        "if hasattr(files, 'tokenize_path'):\n",
        "    with open(files.tokenizer_path(), 'w') as f:\n",
        "        f.write('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')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFyxITiSkCG-"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Veri yollarını belirltiğim yer\n",
        "fake_news_dir = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/90-train/fake'\n",
        "real_news_dir = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/90-train/real'\n",
        "\n",
        "# Veriyi okudum ve etiketledim\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for filename in os.listdir(fake_news_dir):\n",
        "  with open(os.path.join(fake_news_dir, filename), 'r', encoding='utf-8') as f:\n",
        "    texts.append(f.read())\n",
        "    labels.append(0)  # Fake haberler için 0 etiketi\n",
        "\n",
        "for filename in os.listdir(real_news_dir):\n",
        "  with open(os.path.join(real_news_dir, filename), 'r', encoding='utf-8') as f:\n",
        "    texts.append(f.read())\n",
        "    labels.append(1)  # Gerçek haberler için 1 etiketi atama kısmı\n",
        "\n",
        "\n",
        "# BERT tokenizer ve modelini yükledim\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', truncation=True, padding=True)\n",
        "model = BertForSequenceClassification.from_pretrained('dbmdz/bert-base-turkish-cased', num_labels=2)\n",
        "\n",
        "# Veriyi BERT giriş formatına dönüştürme\n",
        "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)  # `max_length` BERT modelinin 512\n",
        "labels_tensor = torch.tensor(labels)\n",
        "\n",
        "# Veriyi TensorDataset'e dönüştürme\n",
        "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels_tensor)\n",
        "\n",
        "# Veriyi DataLoader'a yükleme\n",
        "batch_size = 8\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Modeli eğitme aşaması\n",
        "print(\"Model eğitim\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # Öğrenme oranı\n",
        "num_epochs = 5  # Epoch sayısı\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "  for batch in dataloader:\n",
        "    input_ids, attention_mask, labels = batch\n",
        "    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(**{'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels})\n",
        "    loss = outputs.loss\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  average_loss = total_loss / len(dataloader)\n",
        "  print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}')\n",
        "\n",
        "# Modeli kaydetme\n",
        "model_save_path = '/content/drive/MyDrive/collab1/DOSYALAR/bertdataset_teslim5'\n",
        "model.save_pretrained(model_save_path)\n",
        "\n",
        "print(\"Eğitim tamamlandı.\")\n",
        "\n",
        "\n",
        "#3.6417441056883406e-05 az\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukq-UcqJxGUF"
      },
      "outputs": [],
      "source": [
        "#DİREKT EĞİTİLMİŞ VERİYİ KULLANMA\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertConfig, BertTokenizer, AutoModelForSequenceClassification\n",
        "from torch.optim import Adam\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Config dosyasını ve eğitilmiş modeli yükleme\n",
        "config_path = '/content/drive/MyDrive/collab1/DOSYALAR/bertdataset_teslim5/config.json'\n",
        "model_path = '/content/drive/MyDrive/collab1/DOSYALAR/bertdataset_teslim5'\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
        "config = BertConfig.from_json_file(config_path)\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, pretrained_model, num_labels=2, dropout_rate=0.5):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.pretrained_model = pretrained_model\n",
        "\n",
        "    # Son çıkış katmanı\n",
        "    self.final_layer = nn.Linear(self.pretrained_model.config.hidden_size, num_labels)\n",
        "\n",
        "    # Dropout eklenerek aşırı uydurmayı önledim\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    outputs = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    pooled_output = outputs.last_hidden_state[:, 0]  # CLS token için [:, 0] kullan\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "    logits = self.final_layer(pooled_output)\n",
        "    return logits\n",
        "\n",
        "#  modelimi oluşturdum\n",
        "custom_model = CustomModel(model)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "custom_model.to(device)\n",
        "\n",
        "# Optimizer ve loss fonksiyonu\n",
        "optimizer = Adam(custom_model.parameters(), lr=1e-4)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Tokenizer'ı yükleme\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', truncation=True, padding=True)\n",
        "\n",
        "# Fake ve Real haber veri seti yolları(90-10)dataseti kullanılarak\n",
        "fake_folder_path = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/10-test/fake'\n",
        "real_folder_path = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/10-test/real'\n",
        "\n",
        "# Dosyaları karıştırma işlemi\n",
        "fake_files = [file for file in os.listdir(fake_folder_path) if file.endswith('.txt')]\n",
        "real_files = [file for file in os.listdir(real_folder_path) if file.endswith('.txt')]\n",
        "random.shuffle(fake_files)\n",
        "random.shuffle(real_files)\n",
        "\n",
        "# Doğrulama döngüsü - Her iki haber seti de kullanılacak şekilde ayarladım\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for file_name in fake_files + real_files:\n",
        "  file_path = os.path.join(fake_folder_path, file_name) if file_name in fake_files else os.path.join(real_folder_path, file_name)\n",
        "  with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    file_content = file.read()\n",
        "\n",
        "  # Dosya içeriğini tokenize etme\n",
        "  inputs = tokenizer(file_content, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "  inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "  # Modeli kullanarak tahmin yapma kısmı\n",
        "  predictions = custom_model(**inputs)\n",
        "\n",
        "  # Etiketi belirleme\n",
        "  label = 0 if file_name in fake_files else 1\n",
        "\n",
        "  # Tahmin ve gerçek etiketleri listeye ekleme\n",
        "  true_labels.append(label)\n",
        "  predicted_labels.append(torch.argmax(predictions, dim=1).item())\n",
        "\n",
        "# Confusion matrix'i oluşturma\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Matrisi görselleştirme\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label(tahmin edilen etiket)\")\n",
        "plt.ylabel(\"True Label(doğru etiket)\")\n",
        "plt.show()\n",
        "\n",
        "# Classification report'u yazdırma\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=['Fake', 'Real'])\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Doğruluk oranını hesaplama\n",
        "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "print(f\"Doğruluk Oranı: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Recall, Precision ve F1-Score'u ayrı ayrı yazdırma kısımları\n",
        "precision_fake, recall_fake, f1_score_fake, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=[0], average='binary')\n",
        "precision_real, recall_real, f1_score_real, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=[1], average='binary')\n",
        "\n",
        "print(f\"Fake Haberler İçin:\\n Recall: {recall_fake:.2f}, F1-Score: {f1_score_fake:.2f}\")\n",
        "print(f\"Real Haberler İçin:\\n Recall: {recall_real:.2f}, F1-Score: {f1_score_real:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL9_l7xdxICM"
      },
      "source": [
        "FİNE TUNİNG KISMINI ALTDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-5HGbnCmkIZ"
      },
      "source": [
        "## FİNE TUNİNG 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjdDnBVCmtyY"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import os\n",
        "from transformers import AdamW\n",
        "\n",
        "def read_texts_from_directory(directory):\n",
        "\n",
        "  texts = []\n",
        "  for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".txt\"):\n",
        "      with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        texts.append(text)\n",
        "  return texts\n",
        "\n",
        "# Veri yolları (fine-tuning için)\n",
        "fake_news_dir = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/90-train/fake'\n",
        "real_news_dir = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/90-train/real'\n",
        "\n",
        "# Yüklenen modelin ve konfigürasyonun yolunu belirttim (eğer varsa)\n",
        "config_path = '/content/drive/MyDrive/collab1/DOSYALAR/bertdataset_teslim5/config.json'\n",
        "model_path = '/content/drive/MyDrive/collab1/DOSYALAR/bertdataset_teslim5/model.safetensors'\n",
        "\n",
        "# Model ve konfigürasyon yükleme (eğer varsa, yoksa yeni model oluşturma)\n",
        "if config_path and model_path:\n",
        "  config = BertConfig.from_json_file(config_path)\n",
        "  model = BertForSequenceClassification.from_pretrained(model_path, config=config)\n",
        "  # Donmuş katmanları ayarlama\n",
        "  for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "else:\n",
        "  # Yeni model oluşturma\n",
        "  model = BertForSequenceClassification.from_pretrained('dbmdz/bert-base-turkish-cased')\n",
        "\n",
        "# Tokenizer kısmı\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', truncation=True, padding=True)\n",
        "\n",
        "# Veri setini oluşturma\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_len):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text = str(self.texts[idx])\n",
        "    label = self.labels[idx]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=False,\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'text': text,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'label': torch.tensor(label, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "# Veri kümesini oluşturma\n",
        "# Fake ve real haber metinlerini okudum\n",
        "fake_texts = read_texts_from_directory(fake_news_dir)\n",
        "real_texts = read_texts_from_directory(real_news_dir)\n",
        "labels = [0] * len(fake_texts) + [1] * len(real_texts)  # 0: fake, 1: real\n",
        "\n",
        "# Veri kümesini train ve test olarak ayırdım\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    fake_texts + real_texts, labels, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Veri setlerini oluşturma\n",
        "train_dataset = CustomDataset(train_texts, train_labels, tokenizer, max_len=128)\n",
        "test_dataset = CustomDataset(test_texts, test_labels, tokenizer, max_len=128)\n",
        "\n",
        "# Optimizer ve loss fonksiyonunu tanımla\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# DataLoader'ları oluşturma kısmı\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Device belirleme kısmı\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Fine-tuning işlemi\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  for batch in tqdm(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['label'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # Modelin başarı oranını test etme\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['label'].to(device)\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "      _, predicted = torch.max(outputs.logits, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = correct / total\n",
        "  print(f'Epoch {epoch + 1}/{epochs}, Accuracy: {accuracy}')\n",
        "\n",
        "# Fine-tuning sonrası modeli kaydet\n",
        "model.save_pretrained('/content/drive/MyDrive/collab1/DOSYALAR/fine_tuned_model')\n",
        "'''\n",
        "100%|██████████| 985/985 [52:17<00:00,  3.19s/it]\n",
        "100%|██████████| 110/110 [05:35<00:00,  3.05s/it]\n",
        "Epoch 1/3, Accuracy: 0.973744292237443\n",
        "100%|██████████| 985/985 [52:16<00:00,  3.18s/it]\n",
        "100%|██████████| 110/110 [05:37<00:00,  3.07s/it]\n",
        "Epoch 2/3, Accuracy: 0.978310502283105\n",
        "100%|██████████| 985/985 [52:44<00:00,  3.21s/it]\n",
        "100%|██████████| 110/110 [05:38<00:00,  3.08s/it]\n",
        "Epoch 3/3, Accuracy: 0.9828767123287672\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/collab1/DOSYALAR/fine_tuned_model'\n",
        "\n",
        "#model ayarlama kısmı\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
        "print(type(model))"
      ],
      "metadata": {
        "id": "2KwzOkq378T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ilk **test**"
      ],
      "metadata": {
        "id": "aaOB1gH6KRTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zIQ5oSFxm0P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import Adam\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from transformers import utils\n",
        "\n",
        "# Config dosyasını ve eğitilmiş modeli yükleme\n",
        "config_path = '/content/drive/MyDrive/collab1/fine_tuned_model/config.json'\n",
        "model_path = '/content/drive/MyDrive/collab1/fine_tuned_model/pytorch_model.bin'\n",
        "\n",
        "# Doğrudan model yükleme (BertForSequenceClassification)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, config=config_path, num_labels=2)\n",
        "\n",
        "# Tokenizer'ı yükleme (BERT için)\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', truncation=True, padding=True)\n",
        "\n",
        "# Fake ve Real haber veri seti yolları\n",
        "fake_folder_path = '/content/drive/MyDrive/collab1/SON_DATASET/random10_90(960-8756)/10-test/fake'\n",
        "real_folder_path = '/content/drive/MyDrive/collab1/SON_DATASET/random10_90(960-8756)/10-test/real'\n",
        "\n",
        "# Doğrulama döngüsü\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Dosyaları karıştırma\n",
        "fake_files = [file for file in os.listdir(fake_folder_path) if file.endswith('.txt')]\n",
        "real_files = [file for file in os.listdir(real_folder_path) if file.endswith('.txt')]\n",
        "random.shuffle(fake_files)\n",
        "random.shuffle(real_files)\n",
        "\n",
        "# Tahmin ve değerlendirme\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for file_name in fake_files + real_files:\n",
        "    file_path = os.path.join(fake_folder_path, file_name) if file_name in fake_files else os.path.join(real_folder_path, file_name)\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        file_content = file.read()\n",
        "\n",
        "    # Dosya içeriğini tokenize etme\n",
        "    inputs = tokenizer(file_content, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Tahmin yapma\n",
        "    with torch.no_grad():  # Disable gradient calculation for efficiency during evaluation\n",
        "        predictions = model(**inputs)\n",
        "\n",
        "    # Tahmin edilen etiketi alma\n",
        "    predicted_label = torch.argmax(predictions.logits, dim=1).item()\n",
        "\n",
        "    # Gerçek etiketi belirleme\n",
        "    label = 0 if file_name in fake_files else 1\n",
        "\n",
        "    # Etiketleri listeye ekleme\n",
        "    true_labels.append(label)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Değerlendirme metrikleri\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=['Fake', 'Real'])\n",
        "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "precision_fake, recall_fake, f1_score_fake, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=[0], average='binary')\n",
        "precision_real, recall_real, f1_score_real, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=[1], average='binary')\n",
        "\n",
        "# Sonuçları yazdırma\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n",
        "print(f\"\\nDoğruluk Oranı: {accuracy * 100:.2f}%\")\n",
        "print(f\"Fake Haberler İçin:\\n Recall: {recall_fake:.2f}, F1-Score: {f1_score_fake:.2f}\")\n",
        "print(f\"Real Haberler İçin:\\n Recall: {recall_real:.2f}, F1-Score: {f1_score_real:.2f}\")\n",
        "'''\n",
        "\n",
        "Confusion Matrix:\n",
        " [[449   7]\n",
        " [  0 504]]\n",
        "\n",
        "Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "        Fake       1.00      0.98      0.99       456\n",
        "        Real       0.99      1.00      0.99       504\n",
        "\n",
        "    accuracy                           0.99       960\n",
        "   macro avg       0.99      0.99      0.99       960\n",
        "weighted avg       0.99      0.99      0.99       960\n",
        "\n",
        "\n",
        "Doğruluk Oranı: 99.27%\n",
        "Fake Haberler İçin:\n",
        " Recall: 1.00, F1-Score: 0.99\n",
        "Real Haberler İçin:\n",
        " Recall: 1.00, F1-Score: 0.99\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGRLXo39x-yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## confusion matrix"
      ],
      "metadata": {
        "id": "3uLDopM6KWw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Confusion matrix'i tanımla\n",
        "cm = np.array([[449, 7],\n",
        "               [0, 504]])\n",
        "\n",
        "# Matrisi görselleştir\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "# Eksen etiketlerini ve değerleri ayarla\n",
        "tick_marks = np.arange(len(cm))\n",
        "plt.xticks(tick_marks, ['Fake', 'Real'], rotation=45)\n",
        "plt.yticks(tick_marks, ['Fake', 'Real'])\n",
        "\n",
        "# Matris değerlerini göster\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in np.ndindex(cm.shape):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B1j-AXBGKb-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ORTALAMA TEST LOSS\n"
      ],
      "metadata": {
        "id": "rCCROrVcxfoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import Adam\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from transformers import utils\n",
        "\n",
        "# Config dosyasını ve eğitilmiş modeli yükleme\n",
        "config_path = '/content/drive/MyDrive/collab1/DOSYALAR/fine_tuned_model/config.json'\n",
        "model_path = '/content/drive/MyDrive/collab1/DOSYALAR/fine_tuned_model/pytorch_model.bin'\n",
        "\n",
        "# Doğrudan model yükleme (BertForSequenceClassification)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, config=config_path, num_labels=2)\n",
        "\n",
        "# Tokenizer'ı yükleme (BERT için)\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', truncation=True, padding=True)\n",
        "\n",
        "# Fake ve Real haber veri seti yolları\n",
        "fake_folder_path = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/10-test/fake'\n",
        "real_folder_path = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/10-test/real'\n",
        "\n",
        "# Doğrulama döngüsü\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Dosyaları karıştırma\n",
        "fake_files = [file for file in os.listdir(fake_folder_path) if file.endswith('.txt')]\n",
        "real_files = [file for file in os.listdir(real_folder_path) if file.endswith('.txt')]\n",
        "random.shuffle(fake_files)\n",
        "random.shuffle(real_files)\n",
        "\n",
        "# Kaybı hesaplamak için değişkenler\n",
        "total_loss = 0.0\n",
        "total_examples = 0\n",
        "\n",
        "# Tahmin ve değerlendirme\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()  # Değerlendirme moduna geçiş\n",
        "\n",
        "with torch.no_grad():  # Değerlendirme sırasında gradient hesaplamayı kapat\n",
        "    for file_name in fake_files + real_files:\n",
        "        # Dosya yolunu belirleme\n",
        "        file_path = os.path.join(fake_folder_path, file_name) if file_name in fake_files else os.path.join(real_folder_path, file_name)\n",
        "\n",
        "        # Dosyayı okuma\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Dosya içeriğini tokenize etme\n",
        "        inputs = tokenizer(file_content, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Gerçek etiketi belirleme\n",
        "        label = 0 if file_name in fake_files else 1\n",
        "        labels = torch.tensor([label]).to(device)\n",
        "\n",
        "        # Tahmin yapma ve kaybı hesaplama\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss.item()\n",
        "\n",
        "        # Toplam kaybı ve örnek sayısını güncelleme\n",
        "        total_loss += loss\n",
        "        total_examples += 1\n",
        "\n",
        "        # Tahmin edilen etiketi alma\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "        # Etiketleri listeye ekleme\n",
        "        true_labels.append(label)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "# Ortalama test kaybını hesaplama\n",
        "average_test_loss = total_loss / total_examples\n",
        "\n",
        "# Değerlendirme metrikleri\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=['Fake', 'Real'])\n",
        "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "precision_fake, recall_fake, f1_score_fake, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=[0], average='binary')\n",
        "precision_real, recall_real, f1_score_real, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=[1], average='binary')\n",
        "\n",
        "# Sonuçları yazdırma\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n",
        "print(f\"\\nDoğruluk Oranı: {accuracy * 100:.2f}%\")\n",
        "print(f\"Fake Haberler İçin:\\n Precision: {precision_fake:.2f}, Recall: {recall_fake:.2f}, F1-Score: {f1_score_fake:.2f}\")\n",
        "print(f\"Real Haberler İçin:\\n Precision: {precision_real:.2f}, Recall: {recall_real:.2f}, F1-Score: {f1_score_real:.2f}\")\n",
        "print(f\"\\nOrtalama Test Kaybı: {average_test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "jm2SChj6xjrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSİFİCATİON REPORT XX.XX% HALİ**"
      ],
      "metadata": {
        "id": "ppTYYen6xt9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Config dosyasını ve eğitilmiş modeli yükleme\n",
        "config_path = '/content/drive/MyDrive/collab1/DOSYALAR/fine_tuned_model/config.json'\n",
        "model_path = '/content/drive/MyDrive/collab1/DOSYALAR/fine_tuned_model/pytorch_model.bin'\n",
        "\n",
        "# Doğrudan model yükleme (BertForSequenceClassification)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, config=config_path, num_labels=2)\n",
        "\n",
        "# Tokenizer'ı yükleme (BERT için)\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased', truncation=True, padding=True)\n",
        "\n",
        "# Fake ve Real haber veri seti yolları\n",
        "fake_folder_path = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/10-test/fake'\n",
        "real_folder_path = '/content/drive/MyDrive/collab1/DOSYALAR/SON_DATASET/random10_90(960-8756)/10-test/real'\n",
        "\n",
        "# Doğrulama döngüsü\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Dosyaları karıştırma\n",
        "fake_files = [file for file in os.listdir(fake_folder_path) if file.endswith('.txt')]\n",
        "real_files = [file for file in os.listdir(real_folder_path) if file.endswith('.txt')]\n",
        "random.shuffle(fake_files)\n",
        "random.shuffle(real_files)\n",
        "\n",
        "# Tahmin ve değerlendirme\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for file_name in fake_files + real_files:\n",
        "    file_path = os.path.join(fake_folder_path, file_name) if file_name in fake_files else os.path.join(real_folder_path, file_name)\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        file_content = file.read()\n",
        "\n",
        "    # Dosya içeriğini tokenize etme\n",
        "    inputs = tokenizer(file_content, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Tahmin yapma\n",
        "    with torch.no_grad():  # Disable gradient calculation for efficiency during evaluation\n",
        "        predictions = model(**inputs)\n",
        "\n",
        "    # Tahmin edilen etiketi alma\n",
        "    predicted_label = torch.argmax(predictions.logits, dim=1).item()\n",
        "\n",
        "    # Gerçek etiketi belirleme\n",
        "    label = 0 if file_name in fake_files else 1\n",
        "\n",
        "    # Etiketleri listeye ekleme\n",
        "    true_labels.append(label)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Değerlendirme metrikleri\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=['Fake', 'Real'], output_dict=True)\n",
        "\n",
        "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "precision_fake = class_report['Fake']['precision'] * 100\n",
        "recall_fake = class_report['Fake']['recall'] * 100\n",
        "f1_score_fake = class_report['Fake']['f1-score'] * 100\n",
        "precision_real = class_report['Real']['precision'] * 100\n",
        "recall_real = class_report['Real']['recall'] * 100\n",
        "f1_score_real = class_report['Real']['f1-score'] * 100\n",
        "\n",
        "# Sonuçları yazdırma\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n",
        "print(f\"\\nDoğruluk Oranı: {accuracy * 100:.2f}%\")\n",
        "print(f\"Fake Haberler İçin:\\n Precision: {precision_fake:.2f}%, Recall: {recall_fake:.2f}%, F1-Score: {f1_score_fake:.2f}%\")\n",
        "print(f\"Real Haberler İçin:\\n Precision: {precision_real:.2f}%, Recall: {recall_real:.2f}%, F1-Score: {f1_score_real:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "c2258afaeedc4fb5be0119c2da8b0320",
            "65a476b3f7e14d9480981f33ae28690d",
            "bfd54afe7f4246b1b2212f3da572bcfb",
            "b60ad30ff0554556aea0e781703a8794",
            "e6df3749e1384e51a9418332940c861f",
            "98c3aca56ae74509a6763628acf5acd2",
            "e0845f270797470e9dee4f81e3d728fc",
            "d3d6b3131f0c48f5a51f675c6c4c7e81",
            "cea4f1779730409185c1e135c0dfac09",
            "a2078844aba4402296dd86ec2b3b6bb8",
            "9b222ca6189749b3aa7e207e3e04d0d5",
            "256d08fb4d3d4c278eafe0642559a77e",
            "d1602669829c4f819f7426b38d5c9f65",
            "221e60c37a0a4209b980d3171ad67886",
            "2b2c0dcbe5b64092a3b81ff9b09aa748",
            "6c28fcd192d84e909b2939f534a6d46f",
            "60ad30c38b194a7f91e1733d1df7c4cc",
            "e95cc07b76164c51976607f7aed2772e",
            "c165cf9b88e641d4ac87f58e60d5ddda",
            "b4da4b52ef364813bf1520a6c4f8f26c",
            "5f374eeae3b746629f8a9f3e12c176d7",
            "680f02e7668b4776b503505d7d5c9e80",
            "e9c8e1a890584935bc723437b7a144dd",
            "f1c1f720cc2a4c85a44699fbb755b3eb",
            "7d488eb5a3044bab8fef5cd14fa2dc5f",
            "acddb9f9eb644a0a95ac2d5d86bc1829",
            "6343579468234598a7378ae43d45c597",
            "9675db37c18247b889207281d4edff71",
            "aaa96884309f40d582d6bab4cfd91641",
            "5463c1cee1414652a7736fe125ee2d80",
            "59fe680842ec4bf8b475ea58fb76aed1",
            "3d2a06b350e9454c942e3f4cd92964f8",
            "dcef599fd74e4d38984f057db5867887"
          ]
        },
        "id": "I4Jk8h-KyAOV",
        "outputId": "dbb56200-2165-49d6-c73a-2630ce3ca0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2258afaeedc4fb5be0119c2da8b0320"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "256d08fb4d3d4c278eafe0642559a77e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c8e1a890584935bc723437b7a144dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[445  11]\n",
            " [  0 504]]\n",
            "\n",
            "Classification Report:\n",
            " {'Fake': {'precision': 1.0, 'recall': 0.9758771929824561, 'f1-score': 0.9877913429522752, 'support': 456.0}, 'Real': {'precision': 0.9786407766990292, 'recall': 1.0, 'f1-score': 0.9892051030421982, 'support': 504.0}, 'accuracy': 0.9885416666666667, 'macro avg': {'precision': 0.9893203883495145, 'recall': 0.9879385964912281, 'f1-score': 0.9884982229972368, 'support': 960.0}, 'weighted avg': {'precision': 0.9887864077669903, 'recall': 0.9885416666666667, 'f1-score': 0.9885335669994848, 'support': 960.0}}\n",
            "\n",
            "Doğruluk Oranı: 98.85%\n",
            "Fake Haberler İçin:\n",
            " Precision: 100.00%, Recall: 97.59%, F1-Score: 98.78%\n",
            "Real Haberler İçin:\n",
            " Precision: 97.86%, Recall: 100.00%, F1-Score: 98.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # YANLIŞLIKLA XX.XX% FORMATINI ELDE EDERKEN CONFUSİON MATRİSİNİ SİLDİM BU KOD EN İYİ BERT CONFUSİON MATRİS KODU"
      ],
      "metadata": {
        "id": "snD9ZLbTyyAQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2258afaeedc4fb5be0119c2da8b0320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65a476b3f7e14d9480981f33ae28690d",
              "IPY_MODEL_bfd54afe7f4246b1b2212f3da572bcfb",
              "IPY_MODEL_b60ad30ff0554556aea0e781703a8794"
            ],
            "layout": "IPY_MODEL_e6df3749e1384e51a9418332940c861f"
          }
        },
        "65a476b3f7e14d9480981f33ae28690d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c3aca56ae74509a6763628acf5acd2",
            "placeholder": "​",
            "style": "IPY_MODEL_e0845f270797470e9dee4f81e3d728fc",
            "value": "vocab.txt: 100%"
          }
        },
        "bfd54afe7f4246b1b2212f3da572bcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d6b3131f0c48f5a51f675c6c4c7e81",
            "max": 251003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cea4f1779730409185c1e135c0dfac09",
            "value": 251003
          }
        },
        "b60ad30ff0554556aea0e781703a8794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2078844aba4402296dd86ec2b3b6bb8",
            "placeholder": "​",
            "style": "IPY_MODEL_9b222ca6189749b3aa7e207e3e04d0d5",
            "value": " 251k/251k [00:00&lt;00:00, 1.65MB/s]"
          }
        },
        "e6df3749e1384e51a9418332940c861f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c3aca56ae74509a6763628acf5acd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0845f270797470e9dee4f81e3d728fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3d6b3131f0c48f5a51f675c6c4c7e81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea4f1779730409185c1e135c0dfac09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2078844aba4402296dd86ec2b3b6bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b222ca6189749b3aa7e207e3e04d0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "256d08fb4d3d4c278eafe0642559a77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1602669829c4f819f7426b38d5c9f65",
              "IPY_MODEL_221e60c37a0a4209b980d3171ad67886",
              "IPY_MODEL_2b2c0dcbe5b64092a3b81ff9b09aa748"
            ],
            "layout": "IPY_MODEL_6c28fcd192d84e909b2939f534a6d46f"
          }
        },
        "d1602669829c4f819f7426b38d5c9f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ad30c38b194a7f91e1733d1df7c4cc",
            "placeholder": "​",
            "style": "IPY_MODEL_e95cc07b76164c51976607f7aed2772e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "221e60c37a0a4209b980d3171ad67886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c165cf9b88e641d4ac87f58e60d5ddda",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4da4b52ef364813bf1520a6c4f8f26c",
            "value": 60
          }
        },
        "2b2c0dcbe5b64092a3b81ff9b09aa748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f374eeae3b746629f8a9f3e12c176d7",
            "placeholder": "​",
            "style": "IPY_MODEL_680f02e7668b4776b503505d7d5c9e80",
            "value": " 60.0/60.0 [00:00&lt;00:00, 1.06kB/s]"
          }
        },
        "6c28fcd192d84e909b2939f534a6d46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ad30c38b194a7f91e1733d1df7c4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95cc07b76164c51976607f7aed2772e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c165cf9b88e641d4ac87f58e60d5ddda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4da4b52ef364813bf1520a6c4f8f26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f374eeae3b746629f8a9f3e12c176d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680f02e7668b4776b503505d7d5c9e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9c8e1a890584935bc723437b7a144dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1c1f720cc2a4c85a44699fbb755b3eb",
              "IPY_MODEL_7d488eb5a3044bab8fef5cd14fa2dc5f",
              "IPY_MODEL_acddb9f9eb644a0a95ac2d5d86bc1829"
            ],
            "layout": "IPY_MODEL_6343579468234598a7378ae43d45c597"
          }
        },
        "f1c1f720cc2a4c85a44699fbb755b3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9675db37c18247b889207281d4edff71",
            "placeholder": "​",
            "style": "IPY_MODEL_aaa96884309f40d582d6bab4cfd91641",
            "value": "config.json: 100%"
          }
        },
        "7d488eb5a3044bab8fef5cd14fa2dc5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5463c1cee1414652a7736fe125ee2d80",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59fe680842ec4bf8b475ea58fb76aed1",
            "value": 385
          }
        },
        "acddb9f9eb644a0a95ac2d5d86bc1829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2a06b350e9454c942e3f4cd92964f8",
            "placeholder": "​",
            "style": "IPY_MODEL_dcef599fd74e4d38984f057db5867887",
            "value": " 385/385 [00:00&lt;00:00, 8.23kB/s]"
          }
        },
        "6343579468234598a7378ae43d45c597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9675db37c18247b889207281d4edff71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa96884309f40d582d6bab4cfd91641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5463c1cee1414652a7736fe125ee2d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59fe680842ec4bf8b475ea58fb76aed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2a06b350e9454c942e3f4cd92964f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcef599fd74e4d38984f057db5867887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}